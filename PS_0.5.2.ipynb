{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# part3_neural_network_mnist_and_own_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# scipy.ndimage for rotating image arrays\n",
    "import scipy.ndimage\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_dataset/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...  my_own_images\\2828_my_own_2.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\2828_my_own_3.png\n",
      "0.01\n",
      "1.0\n",
      "loading ...  my_own_images\\2828_my_own_4.png\n",
      "0.01\n",
      "0.93011767\n",
      "loading ...  my_own_images\\2828_my_own_5.png\n",
      "0.01\n",
      "0.86800003\n",
      "loading ...  my_own_images\\2828_my_own_6.png\n",
      "0.01\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images/2828_my_own_?.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.01018198e-04]\n",
      " [4.31851100e-03]\n",
      " [3.89982353e-02]\n",
      " [4.01081897e-03]\n",
      " [8.56055226e-01]\n",
      " [1.01697778e-02]\n",
      " [7.20505551e-03]\n",
      " [1.99763747e-02]\n",
      " [1.34679541e-04]\n",
      " [4.21433121e-04]]\n",
      "network says  4\n",
      "match!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2IEkCDuQBGEHkiDsQBKEHUji/wDnwQ+e428kOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 2\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# part3_neural_network_mnist_backquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9753\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dc31418b70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXYhEkNmFSASZXYhEkNmFSIT/B+i0BUzB+jGqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# part3_neural_network_mnist_data_with_rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 10\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        \n",
    "        ## create rotated variations\n",
    "        # rotated anticlockwise by x degrees\n",
    "        inputs_plusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), 10, cval=0.01, order=1, reshape=False)\n",
    "        n.train(inputs_plusx_img.reshape(784), targets)\n",
    "        # rotated clockwise by x degrees\n",
    "        inputs_minusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -10, cval=0.01, order=1, reshape=False)\n",
    "        n.train(inputs_minusx_img.reshape(784), targets)\n",
    "        \n",
    "        # rotated anticlockwise by 10 degrees\n",
    "        #inputs_plus10_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), 10, cval=0.01, order=1, reshape=False)\n",
    "        #n.train(inputs_plus10_img.reshape(784), targets)\n",
    "        # rotated clockwise by 10 degrees\n",
    "        #inputs_minus10_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -10, cval=0.01, order=1, reshape=False)\n",
    "        #n.train(inputs_minus10_img.reshape(784), targets)\n",
    "        \n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9774\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
